{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multivariate prediction models (no tree heuristics)\n",
        "\n",
        "The multivariate experiments now live in their own notebook and focus on reporting the regularized/logistic models plus the forest-based ensembles (including the BRF track). The old decision-tree heuristics are intentionally omitted per the updated analysis plan.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset and design matrix\n",
        "\n",
        "We reuse the persistence filter so the multivariate models are aligned with the univariate regressions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from analysis_utils import (\n",
        "    load_base_dataset,\n",
        "    engineer_baseline_features,\n",
        "    prepare_persistence_dataset,\n",
        "    evaluate_multivariate_models,\n",
        ")\n",
        "from IPython.display import display\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "raw_df = load_base_dataset()\n",
        "feature_df, feature_sets = engineer_baseline_features(raw_df)\n",
        "persistence_df = prepare_persistence_dataset(feature_df, feature_sets[\"all_features\"])\n",
        "print(f\"Design matrix shape: {persistence_df.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model comparison summary\n",
        "\n",
        "Each pipeline uses stratified 5-fold cross-validation and reports ROC-AUC, PR-AUC, balanced accuracy, F1, and accuracy. The BRF implementation uses the in-repo helper class so we no longer depend on the Colab-only imbalanced-learn install.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "metrics_df, feature_tables = evaluate_multivariate_models(\n",
        "    persistence_df,\n",
        "    feature_sets[\"all_features\"],\n",
        "    target_col=\"aan_persistence\",\n",
        ")\n",
        "print(\"Cross-validated metrics:\")\n",
        "display(metrics_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature importance snapshots\n",
        "\n",
        "Tree-based models expose feature importances. This cell surfaces the top signals per model so we can track stability between BRF and the vanilla random forest.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "for model_name, table in feature_tables.items():\n",
        "    print(f\"\n",
        "Top features for {model_name}\")\n",
        "    display(table.head(20))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}